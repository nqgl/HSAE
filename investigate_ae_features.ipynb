{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoEncoderConfig(seed=49,\n",
      "                  batch_size=512,\n",
      "                  buffer_mult=20000,\n",
      "                  lr=0.0001,\n",
      "                  num_tokens=2000000000,\n",
      "                  l1_coeff=0.002,\n",
      "                  beta1=0.9,\n",
      "                  beta2=0.99,\n",
      "                  dict_mult=16,\n",
      "                  seq_len=128,\n",
      "                  layer=1,\n",
      "                  enc_dtype='fp32',\n",
      "                  model_name='gelu-2l',\n",
      "                  site='z',\n",
      "                  device='cuda',\n",
      "                  remove_rare_dir=False,\n",
      "                  act_size=512,\n",
      "                  flatten_heads=True,\n",
      "                  model_batch_size=64,\n",
      "                  buffer_size=10240000,\n",
      "                  buffer_batches=80000,\n",
      "                  act_name='blocks.1.attn.hook_z',\n",
      "                  dict_size=8192,\n",
      "                  name='gelu-2l_1_8192_z',\n",
      "                  buffer_refresh_ratio=0.2,\n",
      "                  nonlinearity=['relu', {}],\n",
      "                  cosine_l1={'period': 62063, 'range': 0.0},\n",
      "                  experimental_type=None,\n",
      "                  gram_shmidt_trail=5000,\n",
      "                  num_to_resample=128)\n"
     ]
    }
   ],
   "source": [
    "from ae_on_heads_w_keith.z_sae import AutoEncoder, AutoEncoderConfig\n",
    "import ae_on_heads_w_keith.z_sae as z_sae\n",
    "ae = AutoEncoder.load(171, save_dir=\"./models-from-remote/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading config.json: 100%|██████████| 1.28k/1.28k [00:00<00:00, 7.48MB/s]\n",
      "Downloading model_final.pth: 100%|██████████| 227M/227M [04:09<00:00, 910kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gelu-2l into HookedTransformer\n",
      "Changing model dtype to torch.float32\n",
      "Moving model to device:  cuda\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hook_embed': HookPoint(),\n",
       " 'hook_pos_embed': HookPoint(),\n",
       " 'blocks.0.ln1.hook_scale': HookPoint(),\n",
       " 'blocks.0.ln1.hook_normalized': HookPoint(),\n",
       " 'blocks.0.ln2.hook_scale': HookPoint(),\n",
       " 'blocks.0.ln2.hook_normalized': HookPoint(),\n",
       " 'blocks.0.attn.hook_k': HookPoint(),\n",
       " 'blocks.0.attn.hook_q': HookPoint(),\n",
       " 'blocks.0.attn.hook_v': HookPoint(),\n",
       " 'blocks.0.attn.hook_z': HookPoint(),\n",
       " 'blocks.0.attn.hook_attn_scores': HookPoint(),\n",
       " 'blocks.0.attn.hook_pattern': HookPoint(),\n",
       " 'blocks.0.attn.hook_result': HookPoint(),\n",
       " 'blocks.0.mlp.hook_pre': HookPoint(),\n",
       " 'blocks.0.mlp.hook_post': HookPoint(),\n",
       " 'blocks.0.hook_attn_in': HookPoint(),\n",
       " 'blocks.0.hook_q_input': HookPoint(),\n",
       " 'blocks.0.hook_k_input': HookPoint(),\n",
       " 'blocks.0.hook_v_input': HookPoint(),\n",
       " 'blocks.0.hook_mlp_in': HookPoint(),\n",
       " 'blocks.0.hook_attn_out': HookPoint(),\n",
       " 'blocks.0.hook_mlp_out': HookPoint(),\n",
       " 'blocks.0.hook_resid_pre': HookPoint(),\n",
       " 'blocks.0.hook_resid_mid': HookPoint(),\n",
       " 'blocks.0.hook_resid_post': HookPoint(),\n",
       " 'ln_final.hook_scale': HookPoint(),\n",
       " 'ln_final.hook_normalized': HookPoint()}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hook_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
