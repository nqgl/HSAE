{"seed": 49, "batch_size": 512, "buffer_mult": 20000, "lr": 0.0001, "num_tokens": 2000000000, "l1_coeff": 0.0038, "beta1": 0.9, "beta2": 0.99, "dict_mult": 64, "seq_len": 128, "layer": 1, "enc_dtype": "fp32", "model_name": "gelu-2l", "site": "z", "device": "cuda", "remove_rare_dir": false, "act_size": 512, "flatten_heads": true, "model_batch_size": 64, "buffer_size": 10240000, "buffer_batches": 80000, "act_name": "blocks.1.attn.hook_z", "dict_size": 32768, "name": "gelu-2l_1_32768_z", "buffer_refresh_ratio": 0.4, "nonlinearity": ["relu", {}], "cosine_l1": {"period": 620063, "range": 0.0125}, "experimental_type": null, "gram_shmidt_trail": 500, "num_to_resample": 64}